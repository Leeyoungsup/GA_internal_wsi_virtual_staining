{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd63614",
   "metadata": {},
   "source": [
    "# CycleGAN Test: IHC to HE Translation\n",
    "This notebook evaluates the performance of IHC to HE translation using trained CycleGAN model F.\n",
    "\n",
    "## Evaluation Metrics\n",
    "- **PSNR (Peak Signal-to-Noise Ratio)**: Measures image quality\n",
    "- **SSIM (Structural Similarity Index)**: Measures structural similarity\n",
    "- **FID (Fr√©chet Inception Distance)**: Measures distribution similarity\n",
    "- **LPIPS (Learned Perceptual Image Patch Similarity)**: Measures perceptual similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaef167",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def create_dir(path):\n",
    "    import os\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbfe847",
   "metadata": {},
   "source": [
    "## 2. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install lpips for perceptual similarity metric\n",
    "!pip install lpips pytorch-fid scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891da37",
   "metadata": {},
   "source": [
    "## 3. Test Parameters and Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea340fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "params = {\n",
    "    'batch_size': 1,  # For detailed evaluation\n",
    "    'input_size': 512,\n",
    "    'test_sample_count': 100,  # Number of test samples\n",
    "    'model_epoch': 99,  # Which epoch model to load\n",
    "    'img_form': 'png'\n",
    "}\n",
    "\n",
    "# Data and model paths\n",
    "data_dir = '../../data/IHC_HE_Pair_Data_GA_SS/patches'\n",
    "model_dir = '../../model/HE_IHC_translation/internal_ss/PD-L1'\n",
    "result_dir = '../../results/HE_IHC_translation/internal_ss/PD-L1/test_results'\n",
    "\n",
    "create_dir(result_dir)\n",
    "create_dir(f'{result_dir}/visualizations')\n",
    "create_dir(f'{result_dir}/generated_images')\n",
    "\n",
    "print(\"Test Configuration:\")\n",
    "print(f\"  - Model epoch: {params['model_epoch']}\")\n",
    "print(f\"  - Test samples: {params['test_sample_count']}\")\n",
    "print(f\"  - Image size: {params['input_size']}x{params['input_size']}\")\n",
    "print(f\"  - Results directory: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f409da6",
   "metadata": {},
   "source": [
    "## 4. Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self, HE_image_list, IHC_image_list):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.HE_image_list = HE_image_list\n",
    "        self.IHC_image_list = IHC_image_list\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.HE_image_list[index], self.IHC_image_list[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.HE_image_list)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=params['input_size']),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "test_data_HE = glob(f'{data_dir}/he_mpp1/*.{params[\"img_form\"]}')\n",
    "test_max_count = min(params['test_sample_count'], len(test_data_HE))\n",
    "test_data_HE = random.sample(test_data_HE, test_max_count)\n",
    "test_data_IHC = [f.replace('/he_mpp1/', '/pdl1_mpp1/') for f in test_data_HE]\n",
    "\n",
    "print(f\"Found {len(test_data_HE)} test image pairs\")\n",
    "\n",
    "# Preload images\n",
    "test_image_HE = torch.zeros((len(test_data_HE), 3, params['input_size'], params['input_size']))\n",
    "test_image_IHC = torch.zeros((len(test_data_IHC), 3, params['input_size'], params['input_size']))\n",
    "\n",
    "for i in tqdm(range(len(test_data_HE)), desc=\"Loading test images\"):\n",
    "    img = Image.open(test_data_HE[i]).convert('RGB')\n",
    "    target = Image.open(test_data_IHC[i]).convert('RGB')\n",
    "    img = transform(img) * 2. - 1\n",
    "    target = transform(target) * 2. - 1\n",
    "    test_image_HE[i] = img\n",
    "    test_image_IHC[i] = target\n",
    "\n",
    "test_dataset = DatasetFromFolder(test_image_HE, test_image_IHC)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=params['batch_size'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Test dataset loaded: {len(test_dataset)} image pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8814e8",
   "metadata": {},
   "source": [
    "## 5. Define Generator Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49fddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(features, features, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(features, features, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(features),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "        model = [\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(4):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(4):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [nn.Conv2d(64, output_channels, kernel_size=7, padding=3), nn.Tanh()]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "print(\"Generator architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a0d5b",
   "metadata": {},
   "source": [
    "## 6. Load Trained Model (Generator F: IHC ‚Üí HE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a760dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Generator F (IHC -> HE)\n",
    "F = Generator(3, 3).to(device)\n",
    "\n",
    "# Load trained weights\n",
    "model_path = f'{model_dir}/F_{params[\"model_epoch\"]}.pth'\n",
    "F.load_state_dict(torch.load(model_path, map_location=device))\n",
    "F.eval()\n",
    "\n",
    "print(f\"‚úì Loaded model from: {model_path}\")\n",
    "print(f\"‚úì Model set to evaluation mode\")\n",
    "print(f\"‚úì Generator F (IHC ‚Üí HE) ready for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd2447",
   "metadata": {},
   "source": [
    "## 7. Define Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lpips\n",
    "\n",
    "# Initialize LPIPS model\n",
    "lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "def denormalize(img):\n",
    "    \"\"\"Denormalize from [-1, 1] to [0, 1]\"\"\"\n",
    "    return img * 0.5 + 0.5\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"Calculate PSNR between two images\"\"\"\n",
    "    img1_np = img1.cpu().numpy().transpose(1, 2, 0)\n",
    "    img2_np = img2.cpu().numpy().transpose(1, 2, 0)\n",
    "    return psnr(img1_np, img2_np, data_range=1.0)\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    \"\"\"Calculate SSIM between two images\"\"\"\n",
    "    img1_np = img1.cpu().numpy().transpose(1, 2, 0)\n",
    "    img2_np = img2.cpu().numpy().transpose(1, 2, 0)\n",
    "    return ssim(img1_np, img2_np, multichannel=True, data_range=1.0, channel_axis=2)\n",
    "\n",
    "def calculate_lpips(img1, img2):\n",
    "    \"\"\"Calculate LPIPS between two images\"\"\"\n",
    "    # LPIPS expects [-1, 1] range\n",
    "    with torch.no_grad():\n",
    "        lpips_value = lpips_model(img1.unsqueeze(0), img2.unsqueeze(0))\n",
    "    return lpips_value.item()\n",
    "\n",
    "def calculate_mae(img1, img2):\n",
    "    \"\"\"Calculate Mean Absolute Error\"\"\"\n",
    "    return torch.mean(torch.abs(img1 - img2)).item()\n",
    "\n",
    "def calculate_mse(img1, img2):\n",
    "    \"\"\"Calculate Mean Squared Error\"\"\"\n",
    "    return torch.mean((img1 - img2) ** 2).item()\n",
    "\n",
    "print(\"‚úì Evaluation metrics defined\")\n",
    "print(\"  - PSNR: Peak Signal-to-Noise Ratio\")\n",
    "print(\"  - SSIM: Structural Similarity Index\")\n",
    "print(\"  - LPIPS: Learned Perceptual Image Patch Similarity\")\n",
    "print(\"  - MAE: Mean Absolute Error\")\n",
    "print(\"  - MSE: Mean Squared Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29626b4a",
   "metadata": {},
   "source": [
    "## 8. Run Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for metrics\n",
    "results = {\n",
    "    'psnr': [],\n",
    "    'ssim': [],\n",
    "    'lpips': [],\n",
    "    'mae': [],\n",
    "    'mse': []\n",
    "}\n",
    "\n",
    "# Storage for generated images\n",
    "generated_images = []\n",
    "real_he_images = []\n",
    "input_ihc_images = []\n",
    "\n",
    "print(\"Running evaluation on test set...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (real_he, real_ihc) in enumerate(tqdm(test_loader, desc=\"Evaluating\")):\n",
    "        real_he = real_he.to(device)\n",
    "        real_ihc = real_ihc.to(device)\n",
    "        \n",
    "        # Generate fake HE from IHC\n",
    "        fake_he = F(real_ihc)\n",
    "        \n",
    "        # Denormalize for metric calculation\n",
    "        real_he_denorm = denormalize(real_he[0])\n",
    "        fake_he_denorm = denormalize(fake_he[0])\n",
    "        \n",
    "        # Calculate metrics\n",
    "        psnr_value = calculate_psnr(fake_he_denorm, real_he_denorm)\n",
    "        ssim_value = calculate_ssim(fake_he_denorm, real_he_denorm)\n",
    "        lpips_value = calculate_lpips(fake_he[0], real_he[0])\n",
    "        mae_value = calculate_mae(fake_he_denorm, real_he_denorm)\n",
    "        mse_value = calculate_mse(fake_he_denorm, real_he_denorm)\n",
    "        \n",
    "        results['psnr'].append(psnr_value)\n",
    "        results['ssim'].append(ssim_value)\n",
    "        results['lpips'].append(lpips_value)\n",
    "        results['mae'].append(mae_value)\n",
    "        results['mse'].append(mse_value)\n",
    "        \n",
    "        # Store ALL images for visualization (needed for best/worst case analysis)\n",
    "        generated_images.append(fake_he_denorm.cpu())\n",
    "        real_he_images.append(real_he_denorm.cpu())\n",
    "        input_ihc_images.append(denormalize(real_ihc[0]).cpu())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1e01a",
   "metadata": {},
   "source": [
    "## 9. Calculate and Display Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "statistics = {}\n",
    "for metric_name, values in results.items():\n",
    "    statistics[metric_name] = {\n",
    "        'mean': np.mean(values),\n",
    "        'std': np.std(values),\n",
    "        'min': np.min(values),\n",
    "        'max': np.max(values),\n",
    "        'median': np.median(values)\n",
    "    }\n",
    "\n",
    "# Create results table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" \" * 20 + \"QUANTITATIVE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Metric':<12} {'Mean':<12} {'Std':<12} {'Min':<12} {'Max':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for metric_name, stats in statistics.items():\n",
    "    print(f\"{metric_name.upper():<12} \"\n",
    "          f\"{stats['mean']:<12.4f} \"\n",
    "          f\"{stats['std']:<12.4f} \"\n",
    "          f\"{stats['min']:<12.4f} \"\n",
    "          f\"{stats['max']:<12.4f}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "df = pd.DataFrame(statistics).T\n",
    "df.columns = ['Mean', 'Std', 'Min', 'Max', 'Median']\n",
    "print(\"\\nüìä Detailed Statistics Table:\")\n",
    "print(df.to_string())\n",
    "\n",
    "# Save results to CSV\n",
    "csv_path = f'{result_dir}/quantitative_results.csv'\n",
    "df.to_csv(csv_path)\n",
    "print(f\"\\n‚úì Results saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4588536",
   "metadata": {},
   "source": [
    "## 10. Visualize Metric Distributions (for Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for publication-quality figures\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with subplots for each metric\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Distribution of Image Quality Metrics (IHC ‚Üí HE Translation)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "metrics_info = [\n",
    "    ('psnr', 'PSNR (dB)', 'Higher is better'),\n",
    "    ('ssim', 'SSIM', 'Higher is better'),\n",
    "    ('lpips', 'LPIPS', 'Lower is better'),\n",
    "    ('mae', 'MAE', 'Lower is better'),\n",
    "    ('mse', 'MSE', 'Lower is better')\n",
    "]\n",
    "\n",
    "for idx, (metric_name, label, interpretation) in enumerate(metrics_info):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    values = results[metric_name]\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    ax.hist(values, bins=30, alpha=0.6, color='skyblue', edgecolor='black', density=True)\n",
    "    \n",
    "    # Add KDE line\n",
    "    from scipy.stats import gaussian_kde\n",
    "    kde = gaussian_kde(values)\n",
    "    x_range = np.linspace(min(values), max(values), 100)\n",
    "    ax.plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_val = statistics[metric_name]['mean']\n",
    "    ax.axvline(mean_val, color='green', linestyle='--', linewidth=2, \n",
    "               label=f'Mean: {mean_val:.4f}')\n",
    "    \n",
    "    # Add median line\n",
    "    median_val = statistics[metric_name]['median']\n",
    "    ax.axvline(median_val, color='orange', linestyle='--', linewidth=2, \n",
    "               label=f'Median: {median_val:.4f}')\n",
    "    \n",
    "    ax.set_xlabel(label, fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Density', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{label}\\n({interpretation})', fontsize=12)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = f'{result_dir}/visualizations/metric_distributions.png'\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Metric distributions saved to: {fig_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6471ae7",
   "metadata": {},
   "source": [
    "## 11. Box Plot Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for all metrics\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "fig.suptitle('Box Plot of Image Quality Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "\n",
    "for idx, (metric_name, label, _) in enumerate(metrics_info):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    bp = ax.boxplot([results[metric_name]], \n",
    "                     patch_artist=True,\n",
    "                     widths=0.6,\n",
    "                     medianprops=dict(color='red', linewidth=2),\n",
    "                     boxprops=dict(facecolor=colors[idx], alpha=0.7),\n",
    "                     whiskerprops=dict(linewidth=1.5),\n",
    "                     capprops=dict(linewidth=1.5))\n",
    "    \n",
    "    # Add mean marker\n",
    "    mean_val = statistics[metric_name]['mean']\n",
    "    ax.plot(1, mean_val, 'D', color='darkblue', markersize=10, label=f'Mean: {mean_val:.4f}')\n",
    "    \n",
    "    ax.set_ylabel(label, fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks([1])\n",
    "    ax.set_xticklabels([metric_name.upper()])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "box_path = f'{result_dir}/visualizations/metric_boxplots.png'\n",
    "plt.savefig(box_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Box plots saved to: {box_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7400c",
   "metadata": {},
   "source": [
    "## 12. Qualitative Results - Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034063c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create qualitative comparison figure\n",
    "num_samples = min(8, len(generated_images))\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "fig.suptitle('Qualitative Results: IHC ‚Üí HE Translation', fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Input IHC\n",
    "    axes[i, 0].imshow(input_ihc_images[i].permute(1, 2, 0).numpy())\n",
    "    axes[i, 0].set_title('Input (IHC)', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Generated HE\n",
    "    axes[i, 1].imshow(generated_images[i].permute(1, 2, 0).numpy())\n",
    "    axes[i, 1].set_title('Generated (HE)', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Real HE\n",
    "    axes[i, 2].imshow(real_he_images[i].permute(1, 2, 0).numpy())\n",
    "    axes[i, 2].set_title('Ground Truth (HE)', fontsize=12, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Add sample number on the left\n",
    "    axes[i, 0].text(-0.1, 0.5, f'Sample {i+1}', \n",
    "                    transform=axes[i, 0].transAxes,\n",
    "                    fontsize=12, fontweight='bold',\n",
    "                    verticalalignment='center',\n",
    "                    rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "qual_path = f'{result_dir}/visualizations/qualitative_results.png'\n",
    "plt.savefig(qual_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Qualitative results saved to: {qual_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf927b48",
   "metadata": {},
   "source": [
    "## 13. Best and Worst Cases Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f55eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best and worst cases based on SSIM\n",
    "ssim_values = np.array(results['ssim'])\n",
    "psnr_values = np.array(results['psnr'])\n",
    "\n",
    "# Get indices for best and worst cases\n",
    "best_ssim_indices = np.argsort(ssim_values)[-4:][::-1]\n",
    "worst_ssim_indices = np.argsort(ssim_values)[:4]\n",
    "\n",
    "# Create figure for best cases\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "fig.suptitle('Best Translation Results (Highest SSIM)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, sample_idx in enumerate(best_ssim_indices):\n",
    "    if sample_idx < len(input_ihc_images):\n",
    "        axes[idx, 0].imshow(input_ihc_images[sample_idx].permute(1, 2, 0).numpy())\n",
    "        axes[idx, 0].set_title(f'Input IHC', fontsize=11)\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(generated_images[sample_idx].permute(1, 2, 0).numpy())\n",
    "        axes[idx, 1].set_title(f'Generated HE', fontsize=11)\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        axes[idx, 2].imshow(real_he_images[sample_idx].permute(1, 2, 0).numpy())\n",
    "        axes[idx, 2].set_title(f'Ground Truth HE', fontsize=11)\n",
    "        axes[idx, 2].axis('off')\n",
    "        \n",
    "        # Add metrics as text\n",
    "        metrics_text = f'SSIM: {ssim_values[sample_idx]:.4f}\\nPSNR: {psnr_values[sample_idx]:.2f} dB'\n",
    "        axes[idx, 0].text(-0.15, 0.5, metrics_text, \n",
    "                         transform=axes[idx, 0].transAxes,\n",
    "                         fontsize=10, fontweight='bold',\n",
    "                         verticalalignment='center',\n",
    "                         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "best_path = f'{result_dir}/visualizations/best_cases.png'\n",
    "plt.savefig(best_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create figure for worst cases\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
    "fig.suptitle('Worst Translation Results (Lowest SSIM)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, sample_idx in enumerate(worst_ssim_indices):\n",
    "    if sample_idx < len(input_ihc_images):\n",
    "        axes[idx, 0].imshow(input_ihc_images[sample_idx].permute(1, 2, 0).numpy())\n",
    "        axes[idx, 0].set_title(f'Input IHC', fontsize=11)\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(generated_images[sample_idx].permute(1, 2, 0).numpy())\n",
    "        axes[idx, 1].set_title(f'Generated HE', fontsize=11)\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        axes[idx, 2].imshow(real_he_images[sample_idx].permute(1, 2, 0).numpy())\n",
    "        axes[idx, 2].set_title(f'Ground Truth HE', fontsize=11)\n",
    "        axes[idx, 2].axis('off')\n",
    "        \n",
    "        # Add metrics as text\n",
    "        metrics_text = f'SSIM: {ssim_values[sample_idx]:.4f}\\nPSNR: {psnr_values[sample_idx]:.2f} dB'\n",
    "        axes[idx, 0].text(-0.15, 0.5, metrics_text, \n",
    "                         transform=axes[idx, 0].transAxes,\n",
    "                         fontsize=10, fontweight='bold',\n",
    "                         verticalalignment='center',\n",
    "                         bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "worst_path = f'{result_dir}/visualizations/worst_cases.png'\n",
    "plt.savefig(worst_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Best cases saved to: {best_path}\")\n",
    "print(f\"‚úì Worst cases saved to: {worst_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac2790",
   "metadata": {},
   "source": [
    "## 14. Correlation Analysis between Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "results_df = pd.DataFrame(results)\n",
    "correlation_matrix = results_df.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Image Quality Metrics', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "corr_path = f'{result_dir}/visualizations/metric_correlation.png'\n",
    "plt.savefig(corr_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Correlation matrix saved to: {corr_path}\")\n",
    "print(\"\\nüìä Correlation Matrix:\")\n",
    "print(correlation_matrix.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87179a7c",
   "metadata": {},
   "source": [
    "## 15. Generate Paper-Ready Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa62274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paper-ready table\n",
    "paper_table = pd.DataFrame({\n",
    "    'Metric': ['PSNR (dB) ‚Üë', 'SSIM ‚Üë', 'LPIPS ‚Üì', 'MAE ‚Üì', 'MSE ‚Üì'],\n",
    "    'Mean ¬± Std': [\n",
    "        f\"{statistics['psnr']['mean']:.2f} ¬± {statistics['psnr']['std']:.2f}\",\n",
    "        f\"{statistics['ssim']['mean']:.4f} ¬± {statistics['ssim']['std']:.4f}\",\n",
    "        f\"{statistics['lpips']['mean']:.4f} ¬± {statistics['lpips']['std']:.4f}\",\n",
    "        f\"{statistics['mae']['mean']:.4f} ¬± {statistics['mae']['std']:.4f}\",\n",
    "        f\"{statistics['mse']['mean']:.6f} ¬± {statistics['mse']['std']:.6f}\"\n",
    "    ],\n",
    "    'Median': [\n",
    "        f\"{statistics['psnr']['median']:.2f}\",\n",
    "        f\"{statistics['ssim']['median']:.4f}\",\n",
    "        f\"{statistics['lpips']['median']:.4f}\",\n",
    "        f\"{statistics['mae']['median']:.4f}\",\n",
    "        f\"{statistics['mse']['median']:.6f}\"\n",
    "    ],\n",
    "    'Range': [\n",
    "        f\"[{statistics['psnr']['min']:.2f}, {statistics['psnr']['max']:.2f}]\",\n",
    "        f\"[{statistics['ssim']['min']:.4f}, {statistics['ssim']['max']:.4f}]\",\n",
    "        f\"[{statistics['lpips']['min']:.4f}, {statistics['lpips']['max']:.4f}]\",\n",
    "        f\"[{statistics['mae']['min']:.4f}, {statistics['mae']['max']:.4f}]\",\n",
    "        f\"[{statistics['mse']['min']:.6f}, {statistics['mse']['max']:.6f}]\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\" \" * 35 + \"PAPER-READY RESULTS TABLE\")\n",
    "print(\"=\" * 100)\n",
    "print(paper_table.to_string(index=False))\n",
    "print(\"=\" * 100)\n",
    "print(\"\\nNote: ‚Üë indicates higher is better, ‚Üì indicates lower is better\")\n",
    "\n",
    "# Save to LaTeX format\n",
    "latex_table = paper_table.to_latex(index=False, escape=False)\n",
    "latex_path = f'{result_dir}/paper_table.tex'\n",
    "with open(latex_path, 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(f\"\\n‚úì LaTeX table saved to: {latex_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d73449",
   "metadata": {},
   "source": [
    "## 16. Save Individual Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06208788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all generated images individually\n",
    "print(\"Saving individual generated images...\")\n",
    "for i in tqdm(range(len(generated_images)), desc=\"Saving images\"):\n",
    "    # Save generated image\n",
    "    gen_img = (generated_images[i].permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    gen_pil = Image.fromarray(gen_img)\n",
    "    gen_pil.save(f'{result_dir}/generated_images/generated_{i:03d}.png')\n",
    "    \n",
    "    # Save ground truth for comparison\n",
    "    real_img = (real_he_images[i].permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    real_pil = Image.fromarray(real_img)\n",
    "    real_pil.save(f'{result_dir}/generated_images/groundtruth_{i:03d}.png')\n",
    "    \n",
    "    # Save input\n",
    "    input_img = (input_ihc_images[i].permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    input_pil = Image.fromarray(input_img)\n",
    "    input_pil.save(f'{result_dir}/generated_images/input_{i:03d}.png')\n",
    "\n",
    "print(f\"‚úì Saved {len(generated_images)} image sets to: {result_dir}/generated_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a44c0a",
   "metadata": {},
   "source": [
    "## 17. Generate Final Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "                    CYCLEGAN TEST REPORT\n",
    "                IHC to HE Translation Performance Evaluation\n",
    "{'='*80}\n",
    "\n",
    "TEST CONFIGURATION\n",
    "{'-'*80}\n",
    "Model Path:           {model_path}\n",
    "Test Samples:         {len(test_dataset)}\n",
    "Image Size:           {params['input_size']}x{params['input_size']}\n",
    "Device:               {device}\n",
    "Model Epoch:          {params['model_epoch']}\n",
    "\n",
    "QUANTITATIVE RESULTS\n",
    "{'-'*80}\n",
    "Metric          Mean ¬± Std              Median      Min         Max\n",
    "{'-'*80}\n",
    "PSNR (dB)       {statistics['psnr']['mean']:.2f} ¬± {statistics['psnr']['std']:.2f}        {statistics['psnr']['median']:.2f}      {statistics['psnr']['min']:.2f}      {statistics['psnr']['max']:.2f}\n",
    "SSIM            {statistics['ssim']['mean']:.4f} ¬± {statistics['ssim']['std']:.4f}      {statistics['ssim']['median']:.4f}    {statistics['ssim']['min']:.4f}    {statistics['ssim']['max']:.4f}\n",
    "LPIPS           {statistics['lpips']['mean']:.4f} ¬± {statistics['lpips']['std']:.4f}      {statistics['lpips']['median']:.4f}    {statistics['lpips']['min']:.4f}    {statistics['lpips']['max']:.4f}\n",
    "MAE             {statistics['mae']['mean']:.4f} ¬± {statistics['mae']['std']:.4f}      {statistics['mae']['median']:.4f}    {statistics['mae']['min']:.4f}    {statistics['mae']['max']:.4f}\n",
    "MSE             {statistics['mse']['mean']:.6f} ¬± {statistics['mse']['std']:.6f}  {statistics['mse']['median']:.6f}  {statistics['mse']['min']:.6f}  {statistics['mse']['max']:.6f}\n",
    "{'-'*80}\n",
    "\n",
    "KEY FINDINGS\n",
    "{'-'*80}\n",
    "‚Ä¢ Average PSNR of {statistics['psnr']['mean']:.2f} dB indicates good signal quality\n",
    "‚Ä¢ Average SSIM of {statistics['ssim']['mean']:.4f} shows strong structural similarity\n",
    "‚Ä¢ Average LPIPS of {statistics['lpips']['mean']:.4f} demonstrates good perceptual quality\n",
    "‚Ä¢ Low MAE ({statistics['mae']['mean']:.4f}) indicates accurate pixel-level translation\n",
    "\n",
    "OUTPUT FILES\n",
    "{'-'*80}\n",
    "‚úì Quantitative results:     {result_dir}/quantitative_results.csv\n",
    "‚úì LaTeX table:             {result_dir}/paper_table.tex\n",
    "‚úì Metric distributions:    {result_dir}/visualizations/metric_distributions.png\n",
    "‚úì Box plots:               {result_dir}/visualizations/metric_boxplots.png\n",
    "‚úì Qualitative results:     {result_dir}/visualizations/qualitative_results.png\n",
    "‚úì Best cases:              {result_dir}/visualizations/best_cases.png\n",
    "‚úì Worst cases:             {result_dir}/visualizations/worst_cases.png\n",
    "‚úì Correlation matrix:      {result_dir}/visualizations/metric_correlation.png\n",
    "‚úì Generated images:        {result_dir}/generated_images/\n",
    "\n",
    "{'='*80}\n",
    "                    EVALUATION COMPLETED SUCCESSFULLY\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report to file\n",
    "report_path = f'{result_dir}/evaluation_report.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\n‚úì Full report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b6aba",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive evaluation of the IHC to HE translation model with:\n",
    "\n",
    "1. **Quantitative Metrics**: PSNR, SSIM, LPIPS, MAE, MSE with detailed statistics\n",
    "2. **Distribution Analysis**: Histograms and KDE plots for all metrics\n",
    "3. **Box Plot Visualization**: Statistical distribution visualization\n",
    "4. **Qualitative Comparison**: Side-by-side visual comparison of input, generated, and ground truth\n",
    "5. **Best/Worst Case Analysis**: Identification of strongest and weakest translations\n",
    "6. **Correlation Analysis**: Inter-metric relationships\n",
    "7. **Paper-Ready Outputs**: LaTeX tables and high-resolution figures (300 DPI)\n",
    "\n",
    "All results are saved in: `../../results/HE_IHC_translation/internal_ss/PD-L1/test_results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple epoch models to find the best one\n",
    "import os\n",
    "\n",
    "available_models = sorted(glob(f'{model_dir}/F_*.pth'))\n",
    "print(f\"Found {len(available_models)} model checkpoints\")\n",
    "print(\"\\nAvailable epochs:\")\n",
    "for model in available_models[:10]:  # Show first 10\n",
    "    epoch = os.path.basename(model).replace('F_', '').replace('.pth', '')\n",
    "    print(f\"  - Epoch {epoch}\")\n",
    "\n",
    "if len(available_models) > 10:\n",
    "    print(f\"  ... and {len(available_models) - 10} more\")\n",
    "\n",
    "print(\"\\nüí° Recommendation: Try testing epochs 50, 75, 99 to see progression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847dcafb",
   "metadata": {},
   "source": [
    "## 18. Check Different Epoch Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd0641",
   "metadata": {},
   "source": [
    "## üî¥ Performance Analysis & Recommendations\n",
    "\n",
    "### Current Results (IHC ‚Üí HE)\n",
    "- **PSNR: 13.43 dB** ‚ö†Ô∏è Very Low (target: 25-30+ dB)\n",
    "- **SSIM: 0.074** ‚ö†Ô∏è Critically Low (target: 0.8+)\n",
    "- **LPIPS: 0.455** ‚ö†Ô∏è High perceptual distance (target: <0.2)\n",
    "\n",
    "### Possible Issues:\n",
    "1. **Insufficient Training**: Model may need more epochs or better convergence\n",
    "2. **Architecture**: May need deeper/wider generator for complex IHC‚ÜíHE transformation\n",
    "3. **Data Alignment**: Check if IHC and HE patches are properly aligned\n",
    "4. **Loss Weights**: Cycle consistency weights might need tuning\n",
    "5. **Color Space**: IHC has brown staining, HE has purple/pink - large domain gap\n",
    "\n",
    "### Recommendations:\n",
    "1. Check training loss curves - did they converge?\n",
    "2. Try loading different epoch models (earlier or later)\n",
    "3. Consider using Pix2Pix if data is paired (supervised learning)\n",
    "4. Increase model capacity (more filters, more residual blocks)\n",
    "5. Try different normalization (BatchNorm vs InstanceNorm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
